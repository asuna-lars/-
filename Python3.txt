Программа 1.
mglearn.plots.plot_linear_regression_wave()
Out[25]:
w[0]:0.213806 b:-0.091854

Программа 2.( линейная регрессия)
from sklearn.linear_model import LinearRegression
X, y = mglearn.datasets.make_wave(n_samples=60)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)
lr = LinearRegression().fit(X_train, y_train)
print("lr.coef_: {}".format(lr.coef_))
print("lr.intercept_: {}".format(lr.intercept_))
Out[27]:
lr.coef_: [0.394]
lr.intercept_: -0.031804343026759746
print("Правильность на обучающем наборе: {:.2f}".format(lr.score(X_train, y_train)))
print("Правильность на тестовом наборе: {:.2f}".format(lr.score(X_test, y_test)))
Out[28]:
Правильность на обучающем наборе:0.67
Правильность на тестовом наборе:0.66

Программа 3.(гребневая регрессия)
from sklearn.linear_model import Ridge
ridge = Ridge().fit(X_train, y_train)
print("Правильность на обучающем наборе: {:.2f}".format(ridge.score(X_train, y_train)))
print("Правильность на тестовом наборе: {:.2f}".format(ridge.score(X_test, y_test)))
Out[31]:
Правильность на обучающем наборе:0.89
Правильность на тестовом наборе:0.75

Программа 4.
from sklearn.linear_model import Ridge
ridge10 = Ridge(alpha=10).fit(X_train, y_train)
print("Правильностьнаобучающемнаборе: {:.2f}".format(ridge10.score(X_train, y_train)))
print("Правильностьнатестовомнаборе: {:.2f}".format(ridge10.score(X_test, y_test)))
Out[32]:
Правильность на обучающем наборе:0.79
Правильность на тестовом наборе:0.64

Программа 5.
from sklearn.linear_model import Lasso
lasso = Lasso().fit(X_train, y_train)
print("Правильность на обучающем наборе: {:.2f}".format(lasso.score(X_train, y_train)))
print("Правильность на контрольном наборе: {:.2f}".format(lasso.score(X_test, y_test)))
print("Количество использованных признаков: {}".format(np.sum(lasso.coef_ !=0)))
Out[36]:
Правильность на обучающем наборе:0.29
Правильность на контрольном наборе:0.21
Количество использованных признаков:4

Программа 6.
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
X, y = mglearn.datasets.make_forge()
fig, axes = plt.subplots(1,2, figsize=(10,3))
for model, ax in zip([LinearSVC(), LogisticRegression()], axes):
clf = model.fit(X, y)
mglearn.plots.plot_2d_separator(clf, X, fill = False, eps = 0.5, ax = ax, alpha = .7)
mglearn.discrete_scatter(X[:,0], X[:,1], y, ax=ax)
ax.set_title("{}".format(clf.__class__.__name__))
ax.set_xlabel("Признак 0")
ax.set_ylabel("Признак 1")
axes[0].legend()

Программа 7.
mglearn.plots.plot_2d_classification(linear_svm, X, fill=True, alpha = .7)
mglearn.discrete_scatter(X[:,0], X[:,1], y)
line = np.linspace(-15,15)
for coef, intercept, color inzip(linear_svm.coef_, linear_svm.intercept_,
['b','r','g']):
plt.plot(line,-(line * coef[0]+ intercept)/ coef[1], c=color)
plt.legend(['Класс 0','Класс 1','Класс 2','Линия класса 0','Линия класса 1',
'Линия класса 2'], loc = (1.01, 0.3))
plt.xlabel("Признак 0")
plt.ylabel("Признак 1")

